{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"out_p_a1_given_q_xeff\"\n",
    "# import data\n",
    "data = pd.read_pickle(f\"{outdir}/p_a1_given_q_xeff.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>xeff</th>\n",
       "      <th>a1</th>\n",
       "      <th>p_a1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[1.0680033419862862, 1.0678605941877117, 1.067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[0.7832345001188603, 0.7843442342552497, 0.784...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[0.2064128256513026, 0.2080031807101176, 0.209...</td>\n",
       "      <td>[0.0003581317510958827, 0.0006423405154926148,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[0.6112224448897795, 0.6120015582266737, 0.612...</td>\n",
       "      <td>[0.003378646421929789, 0.004692188317429458, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 0.002004008016032064, 0.0040080160320641...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q  xeff                                                 a1  \\\n",
       "0    0.0  -1.0  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "1    0.0  -0.8  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "2    0.0  -0.6  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "3    0.0  -0.4  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "4    0.0  -0.2  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "..   ...   ...                                                ...   \n",
       "116  1.0   0.2  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "117  1.0   0.4  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "118  1.0   0.6  [0.2064128256513026, 0.2080031807101176, 0.209...   \n",
       "119  1.0   0.8  [0.6112224448897795, 0.6120015582266737, 0.612...   \n",
       "120  1.0   1.0  [0.0, 0.002004008016032064, 0.0040080160320641...   \n",
       "\n",
       "                                                  p_a1  \n",
       "0    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "1    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "2    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "3    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "4    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "..                                                 ...  \n",
       "116  [1.0680033419862862, 1.0678605941877117, 1.067...  \n",
       "117  [0.7832345001188603, 0.7843442342552497, 0.784...  \n",
       "118  [0.0003581317510958827, 0.0006423405154926148,...  \n",
       "119  [0.003378646421929789, 0.004692188317429458, 0...  \n",
       "120  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  \n",
       "\n",
       "[121 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data contains nans, drop them so that they wont cause problems later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([0,1,2,3,4,5,6,7,8,9,10,11,21,22,32,33,43,44,54,55,65,66,76,77,87,88,98,99,109,110,120], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stupid way of getting everything to a numpy array with dtyoe = float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = []\n",
    "for i in range(len(data)):\n",
    "    a1.append(data['a1'][i])\n",
    "a1 = np.array(a1)\n",
    "p = []\n",
    "for i in range(len(data)):\n",
    "    p.append(data['p_a1'][i])\n",
    "p = np.array(p)\n",
    "q = data['q'].values\n",
    "xeff = data['xeff'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import normalize\n",
    "# p_norm = normalize(p,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_q, test_q, train_xeff, test_xeff, train_p, test_p, train_a1, test_a1 \\\n",
    "= train_test_split(q, xeff, p, a1,\n",
    " test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair q and xeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_xeff = np.stack((train_q, train_xeff), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "        Activation, BatchNormalization, Concatenate, Dense, Dropout, Multiply,\n",
    "        Embedding, Flatten, Input, Reshape, LeakyReLU, Conv2D, Conv2DTranspose) \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (500,500)       # 500 a1, 500 p\n",
    "z_dim = 32                   # latent space dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator model, which generate the desired probability density distritution\n",
    "# given the latent space input\n",
    "def generator_model(z_dim):\n",
    "    model = Model()\n",
    "    \n",
    "    Input = \n",
    "    model.add(Dense(256 * 7 * 7, input_dim=z_dim,))\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "    return model\n",
    "\n",
    "# generator input \n",
    "def generator(z_dim):\n",
    "    # latent input\n",
    "    z = Input(shape=(z_dim, ))\n",
    "    # label input\n",
    "    label = Input(shape=(1, ), dtype='int32')\n",
    "    # convert label to embedding\n",
    "    label_embedding = Embedding(n_class, z_dim)(label)\n",
    "\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    # dot product two inputs\n",
    "    joined_representation = Multiply()([z, label_embedding])\n",
    "\n",
    "    generator = generator_model(z_dim)\n",
    "\n",
    "    conditioned_img = generator(joined_representation)\n",
    "\n",
    "    model =  Model([z, label], conditioned_img)\n",
    "    # save model blueprint to image\n",
    "    plot_model(model,'generator.jpg',show_shapes=True,show_dtype=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Discriminator takes the p,a1 as data and q, xeff as 'labels', so that the data is conditioned on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator CNN model\n",
    "def discriminator_model(img_shape):\n",
    "    # 2 inputs\n",
    "    in_label = Input(shape=(2,))\n",
    "    in_data = Input(shape=(500,500))\n",
    "    # merged together\n",
    "    merged = Concatenate()([in_label, in_data])\n",
    "    Flatten = Flatten()(merged)\n",
    "    x = Dense(512,activation='relu')(Flatten)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "541143602329a03f71f32a0a160c785fb8ee263553dc2658377783b6f80d17e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
